{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability and simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats, you've made it to the second half of this textbook. Here's a bold claim a: *the study of probability is the key to tackling uncertainty*.\n",
    "\n",
    "What exactly does the study of probability entail? And if it's so powerful, how can we use computers to leverage that power?\n",
    "\n",
    "Let's dive in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities in our daily lives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply, a {dterm}`probability` is a measure of how likely something is to happen.\n",
    "\n",
    "We rely on likelihood in our daily lives whenever we're faced with a question that doesn't have a definite answer. These often come in the categories of questions about the future, <font color=\"blue\">[\"Can I get an A without going to class?\"], or questions subject to debate, [\"Does ...\", \"Did jury unfair?\"].\n",
    "\n",
    "While all of the questions we could possibly ask have some fundamental, universal truth, much like quantum physics the true answer remains unknown until it's been observed! This means, in order to get a 100% certain answer, we need to wait for the future to arrive, or for an investigation so thorough that there's not even a shred of doubt remaining.\n",
    "\n",
    "That's less than ideal. There must be a way to answer the question without waiting.\n",
    "\n",
    "Enter *probabilities*. In real life when we're faced with a question with an uncertain answer we usually offer whichever answer is *most likely*. We say things like, [\"I'm 80% sure that I can get an A\"], or [\"There's a pretty good chance the election was rigged.\"] How we arrive at that measure of '50%', or the math that lead us to 'pretty good chance' all boils down to calculating probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A semi-formal introduction to probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally, a probability of an event, written as $P(\\text{event})$ is the likelihood that the event will occur expressed as a value between $0$ and $1$. A probability of $0$ means the event will theoretically never happen, $1$ means the event is theoretically certain to happen, and $0.5$ means the event is just as likely to happen or not happen.\n",
    "\n",
    "$$0 \\leq P(\\text{event}) \\leq 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, when we flip a fair coin, the probability that it lands showing Heads is $P(\\text{Heads}) = \\frac{1}{2}$ (or $0.5$ or $50\\%$). We know this intuitively, but let's formalize the math a little bit to figure out where that number comes from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "You may notice that probabilities are defined as between 0 and 1, but sometimes we use a percentage. Mathematically they're the same, $100\\% = 100 \\textit{ per cent} = \\frac{100}{100} = 1.$ But while percents can be nice in spoken language, you should stay consistent and always work with probabilities expressed as fractions or decimals between 0 and 1 when performing calculations. This will make your life much easier and prevent you from pulling out your hair due to decimal place errors!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're learning about data *science*, let's define the terminology of probability in a scientific manner. This terminology is consistent across most probability and statistics textbooks, too.\n",
    "\n",
    "Each time we face an uncertain outcome -- like flipping a fair coin -- we're essentially conducting an *experiment*. An {dterm}`experiment` is a process with a set of distinct possible {dterm}`outcomes`, only one of which can be the true result of a single trial. We can conduct many trials of the experiment, but the each time we are uncertain which specific outcome will be the result. In this example, our experiment is a single coin flip and the possible outcomes are Heads and Tails, often written as a mathematical set, $\\{\\text{Heads}, \\text{Tails}\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All things equal\n",
    "\n",
    "In the case of flipping a coin, rolling a die, or any other experiment where all outcomes are equally likely, the probability of any given outcome is one divided by the total number of possible outcomes. So, for flipping a coin the probability of any outcome is $\\frac{1}{2}$, for a six-sided die the probability of any outcome is $\\frac{1}{6}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{equally-likely outcome}) = \\frac{1}{\\text{# of possible outcomes}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "If all outcomes of a process are equally likely, we usually call that process 'random'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, we'll use NumPy's `random.choice` function to choose one outcome from a list of possible outcomes. The code below essentially conducts an experiment of a single coin flip, then checks whether or not it landed on 'Heads' by using a {dterm}`comparison operator`. If we run the cell a bunch of times, we should expect that it'll return True roughly half of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "outcome = np.random.choice(['Heads', 'Tails'])\n",
    "\n",
    "outcome == 'Heads'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you tire your fingers running that cell dozens of times, you should know that NumPy makes it easy to run multiple trials of the experiment by specifying a second argument, `size=`. This time, we tell NumPy to choose randomly between Heads or Tails ten times, and the result is an array of the outcome of each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed of zero results in 2 heads out of 10... could be useful.\n",
    "# np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">[! should we introduce the for loop here instead? might make more sense to do loops and append now...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = np.random.choice(['Heads', 'Tails'], size=10)\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're working with an array we can do element-wise comparisons in order to check if each outcome resulted in Heads or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes == 'Heads'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you know that you can count how many `True`s there are in a sequence by just taking the `sum` of that sequence? Let's try that now in order to find out how many of our ten coin flips resulted in Heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(outcomes == 'Heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collections of outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to something with more than two outcomes, like rolling a fair six-sided die. If you're playing a game that involes a die, you might be able to win if you roll a one *or* if you roll a two, so you'd be interested in the chances of getting either of these outcomes. The probability one-of-multiple outcomes occurring, like rolling a one *or* a two, is equal to the sum of each individual probability.\n",
    "\n",
    "$$P(\\text{one or two}) = P(\\text{one}) + P(\\text{two}) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}$$\n",
    "\n",
    "What you've just stumbled upon is called an *event*. An {dterm}`event` is a collection of outcomes where we're interested in finding the probability of any of those outcomes occurring. If we define the event $\\text{win}$ as rolling a one or a two, (often expressed as a mathematical set) $\\text{win} = \\{\\text{one, two}\\}$, then calculating the probability of $\\text{win}$ is the exact same calculation as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">[! Worried that the set notation will be confusing -- if they forget the brackets and write P(one, two) = P(one or two) then we could be sabotaging ourselves!]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{win}) = P(\\{\\text{one, two}\\}) = P(\\text{one or two})$$\n",
    "\n",
    "From these two facts, it follows that the probability of any event is always just the sum of the probabilities of each outcome that satisfies the event.\n",
    "\n",
    "$$P(\\text{event}) = \\sum_{\\text{all outcomes in event}} P(\\text{outcome})$$\n",
    "\n",
    "When we're in the scenario of equally-likely outcomes, it so happens that it doesn't matter *which* outcomes are in our event, merely *how many* outcomes are in our event. By recognizing the repeated addition of $1$ in the numerator when we add the probabilities of equally-likely outcomes we can deduce a simpler way to calculate the probability of an event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{event with equally-likely outcomes}) = \\frac{\\text{# outcomes in event}}{\\text{total # possible outcomes}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "The realm of equally-likely outcomes is part of the study of 'Classical Probability'. Since the probabilities of outcomes and events are based on counting how many outcomes there are, and how many we're interested in, this study is tackled primarily using combinatorics -- you'll see more of those in DSC 40A and your stats classes! \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like an event can be broken down into multiple *or*'s mathematically, we can do the exact same thing in our code by using the `or` operator to string together multiple equality checks. In the code below, we're running an experiment of a single die roll, and checking if the winning event is satisfied by the roll. Based on the math above, we should expect the following cell to return True roughly a third of the times we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = np.random.choice([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "outcome == 1 or outcome == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, NumPy makes it easy to run many trials of the experiment, see how many of them satisfy our event, and then sum up the Trues to get a count. Only catch: we need to use the `|` operator (and parentheses!) whenever we're trying to perform elementwise logic on arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = np.random.choice(range(1,6+1), 100)\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(\n",
    "    (outcomes == 1) | (outcomes == 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">[! maybe make a bigger point that `or` is for single values, `|` is for element-wise]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humorously, we can also find the probability of the event containing zero outcomes, $\\text{nothing} = \\{\\}$. Asking for the probability of this empty event is essentially asking for the probability that our experiment produces none of the possible results thus violates all universal laws. If this sounds impossible to you, you're right. The probability of an empty event is zero. Whew, existential crisis avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other end of the spectrum, we could ask for the probability that any of our outcomes happen by specifying the event containing all outcomes -- statisticians have a special word for this event, called the 'sample space' -- $\\text{sample space} = \\{\\text{outcome}_1,\\ldots,\\text{outcome}_n\\}$. Necessarily our experiment must produce one of the possible outcomes, so the probability of observing an outcome sample space is one. Because we also know that the probability of an event is equal to the sum of the probabilities of each outcome it contains, we can equivalently state that the probabilities of all possible outcomes sum to one.\n",
    "\n",
    "$$\\sum_{\\text{all possible outcomes}} P(\\text{outcome}) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the probability that some event does *not* happen is one minus the probability that it does. You can think of this as taking the sample space and removing the event that we're interested in *not* happening.\n",
    "\n",
    "$$P(\\text{not event}) = 1 - P(\\text{event})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A general way to find probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code examples above, we ran an experiment many times and expected a certain number of them to satisfy our event because we already knew the probability of the event.\n",
    "\n",
    "What if we ran our code for flipping a coin 100 times and only saw that 20 of them showed up as Heads? Naturally we would start to suspect that the probability of flipping a Heads is closer to $\\frac{20}{100}=0.2$ rather than $0.5$, right?\n",
    "\n",
    "Aha! If you agreed, then you already have intuition for the primary definition of probability that beginning data scientists use, called the 'frequentist' approach. This definition operates without the need for any assumptions about the likelihoods of our outcomes. We calculate the probability of some event happening as approximately the number of times we observed it divided by the total number of observations we made. This is often called the 'experimental probability' (to distinguish it from the universal truth that it approximates).\n",
    "\n",
    "$$P(\\text{event}) \\approx \\frac{\\text{# times event observed}}{\\text{total # observations}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remember our introduction to {dterm}`proportions` in Exploring Data, you'll notice that the calculation of an experimental probability is the exact same as the calculation of a proportion! <font color=\"blue\">[! Expand on this?] [we leverage computers to crunch probabilities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of observations is important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approximation of an experimental probability gets closer and closer to the true underlying probability as the number of observations increases. Formally, the equality holds once you've made infinite observations... in practice it can be pretty challenging to make infinite observations!\n",
    "\n",
    "Unfortunately, with few observations there's a good chance (!) that the experimental probability will be inaccurate simply due to randomness inherent to the experiment. In other words: You wouldn't expect to get exactly five Heads *every* time you flip ten coins. Sometimes you'll get more, sometimes less... it's possible that you might even see no Heads (though very rare)!\n",
    "\n",
    "Furthermore, the fewer observations that are made, the more extreme each deviation seems, and the less precise our answer can be. If you only make ten observations, then a single unit change in the numerator causes a change of 0.1 (10%) in the resulting probability, and we can only be precise up to the nearest 0.1. Whereas if we were to make one-hundred observations, then we can be precise up to the nearest 0.01.\n",
    "\n",
    "Because it's never possible to make infinite observations, we must accept the use of a smaller number of observations, but remain cognizant that we lose both accuracy and precision as the number of observations decreases -- we'll talk about how to deal with this more when we discuss sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex experiments and simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've worked with relatively simple experiments with straightforwards. We've flipped a single coin, or rolled a single die, and we are interested in purely the result of that flip or roll. But the real world throws much more challenging events at us. How would you handle an experiment in which you roll two dice? What if you had three dice? Three dice followed by a coin flip? There is math involving combinatorics that you can learn in order to calculate the probabilities of each outcome for these examples, but we'll save that for your math courses!\n",
    "\n",
    "Fortunately, we can rely on the frequentist approach and use computers to simulate a bunch of experiments, allowing us to approximate the true probability of any specified event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Birthday Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you look around your classroom and count a total of 23 students (including yourself). Assuming it's equally-likely for someone's birthday to be on any day of the year (ignoring February 29th), would you expect that at least two people in your class share the same birthday?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether or not we 'expect' that at one pair of classmates share the same birthday is dependent on whether or not the corresponding probability is greater than 50%. So, we need a way to find that probability!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To utilize the frequentist approach and estimate the probability we would need to repeat the experiment many times. That means we could physically go out into the world, gather 23 people from the global population and see if any of them share a birthday, then repeat this a bunch of times... good luck with that! You'll be hard pressed to find the time, willingness, or funding necessary to conduct such as study. Because we have an assumption about the probability of each birthday occurring, we can rely on a computer simulation instead!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conducting a probability simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time we conduct a simulation to estimate a probability, we follow the same four general steps:\n",
    "\n",
    "1. Frame your experiment, outcomes, and event of interest\n",
    "2. Write the code to simulate a single outcome\n",
    "3. Call that code lots of times and keep track of the outcomes\n",
    "4. Calculate the experimental probability of your event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Frame the experiment\n",
    "\n",
    "Starting with step one of simulation, let's frame the experiment, outcomes, and event of interest an attempt to get a better grasp of this unintuitive Birthday Problem.\n",
    "\n",
    "- Experiment: Select 23 birthdays at random from 1 to 365 (inclusive) and see whether or not there are any shared birthdays  \n",
    "- Outcomes: $\\{\\text{True}, \\text{False}\\}$  \n",
    "- Event: $\\{\\text{True}\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Simulate a single trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to step two, we translate the description of our experiment into Python code. We can use NumPy to easily generate 23 random birthdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classmate_birthdays = np.random.choice(range(1, 365+1), 23)\n",
    "classmate_birthdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see if any of the birthdays are shared, we can check if the number of unique elements in our array of birthdays is smaller than the total number of randomly selected birthdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_birthdays = np.unique(classmate_birthdays)\n",
    "\n",
    "any_shared = len(unique_birthdays) < len(classmate_birthdays)\n",
    "any_shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have working code to simulate a single trial of the experiment, we want to wrap it all into a function so that we can easily call it in the future. (Remember to write a docstring or some comments to help *future you* remember what your code does!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_birthday_experiment():\n",
    "    \"\"\"\n",
    "    Performs a single trial of the Birthday Problem experiment.\n",
    "    \n",
    "    - Selects 23 birthdays at random (1 to 365)\n",
    "    - Returns whether or not any birthdays are shared by multiple people\n",
    "    \"\"\"\n",
    "    \n",
    "    classmate_birthdays = np.random.choice(range(1, 365+1), 23)\n",
    "    \n",
    "    unique_birthdays = np.unique(classmate_birthdays)\n",
    "    \n",
    "    any_shared = len(unique_birthdays) < len(classmate_birthdays)\n",
    "    \n",
    "    return any_shared\n",
    "\n",
    "run_birthday_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Use a `for` loop to perform multiple trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arriving at step three, we need a way to run this custom function multiple times -- how do we do this? In programming the concept of repeatedly executing code is called 'iteration', and it is commonly carried out in Python using a **`for` loop**.\n",
    "\n",
    "The syntax for running something many times is as follows. Just like with functions, the code you want repeated must be indented.\n",
    "\n",
    "```html\n",
    "for i in range(<number_of_repetitions>):\n",
    "    \n",
    "    <code_that_you_want_run_multiple_times>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens if we double a number three times using a for loop, then get that variable as an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_me = 1\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    double_me = double_me * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing is returned by the for loop, it merely runs its contained code multiple times. The effects are persistent though, and if we check the value of `double_me` we'll see that it has indeed been doubled three times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running a simulation, we'd like to keep track of the outcome of each trial, not just the final outcome. Since we know that we can modify variables within a for loop, we can keep track of our outcomes by creating an empty list and then adding each trial to it within the loop. This is accomplished by using the `.append` list method with the outcome as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = []\n",
    "\n",
    "outcomes.append(True)\n",
    "\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this all together, let's finally run out Birthday Problem experiment a handful of times. Start by creating the empty list which will contain our outcomes and defining how many trials we will conduct.\n",
    "\n",
    "Recall from our introduction to frequentist probability that as the number of observations increases our probability approximation will be better. Before you try to run an infinite number of trials, remember that the more iterations we simulate, the longer our code will take to run. But since this simulation doesn't take too much processing power, let's start with $10,000$ trials. Make sure to keep track of this number, since we'll need it to calculate the experimental probability. Then, within our loop append the outcome of a single experiment run to our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 10_000\n",
    "outcomes = []\n",
    "\n",
    "for i in range(trials):\n",
    "    \n",
    "    any_shared = run_birthday_experiment()\n",
    "    outcomes.append(any_shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Calculate the experimental probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final step four, we just need to use the formula for experimental probability to calculate an approximate probability for the chance that at least one pair of our 23 classmates will share a birthday. Recall this formula is $P = \\frac{\\text{# times event observed}}{\\text{total # of trials}}$.\n",
    "\n",
    "Back outside of the loop, let's turn our list into a NumPy array in order to unlock the extra capabilities that NumPy provides like element-wise comparisons. To count how many times our outcomes satisfied our event, we can use a comparison operator on our outcome array, then take the sum. Finally, we divide by the number of trials to arrive at our approximate probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = np.array(outcomes)\n",
    "sum(outcomes == True) / trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No way, really? There's over a 50% chance that someone in our class of 23 students will share their birthday with someone else in the class? Yup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this simulation approach blends the classical and frequentist approaches\n",
    "    - classical for coin flip probability (using assumptions!)\n",
    "    - frequentist for prob of result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">[! seems like this could easily segue into either distributions or HT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Old work / Staging area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if you meet someone new, when does their birthday occur? (ignoring leap years)\n",
    "- unsure, a bit like Schrodinger's cat -- we don't know the truth until it is observed!\n",
    "- now is a good time for a 'probabilistic model'\n",
    "- assume that birthdays are uniformly distrbuted -- equally likely\n",
    "- with all possible outcomes equally likely, the probability of their birthday being on any given day is 1/365 (again, ignoring leap years)\n",
    "- we could find probabilities of an event -- a collection of outcomes\n",
    "- other math properties somehow\n",
    "- if we were to ask people we'd expect to find\n",
    "\n",
    "- but should we question the validity of our model?\n",
    "- say we're trying to determine which day is actually most likely for us to guess correct\n",
    "- we essentially do the reverse of our expectation -- welcome to the 'frequentist' approach\n",
    "- the probability is approximately the number of times observed over the number of trials -- getting closer to truth as the number of trials gets closer to infinity\n",
    "\n",
    "- we can't ask infinite people though! there are only 7bn people. Wait, we can't ask 7bn people either! Enter: sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's entertain an example that we should all be familiar with: flipping a coin. Unbeknownst to most, flipping a coin is an incredibly complex process whose outcome depends on a nigh infinite number of factors: the starting orientation of the coin, the strength with which it's flipped, the presence of a breeze, the wear and tear of the coin... et cetera... all culminating with whether or not the catcher chooses to keep the coin resting in their palm or slap it on to the back of their other hand after they catch it! But in practice, we don't think about a coin flip this way. Not only is it infeasible to attempt to calculate all of those factors (lest even name them all!), but we can nicely summarize the coin flipping process with a simple {dterm}`probabilitistic model`: we expect that half of the time the coin will show Heads, and half of the time it will show Tails.\n",
    "\n",
    "The probability of a Heads is thus 0.5, written mathematically as $P(\\text{Heads})=0.5$. The probability of Tails is in this case the same, $P(\\text{Tails})=0.5$.\n",
    "\n",
    "In life we call processes like flipping a coin *random*, with outcomes that are subject to *chance*. Any time you hear these words, understand that a probabilistic model is at play, and therefore any questions about this process must be answered by working with the likelihood (probabilities) of each outcome using that model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The math of probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get too far ahead of ourselves, there are a couple properties that all probabilities satisfy which prove useful whenever you're working with them.\n",
    "\n",
    "- All probabilities are between $0$ and $1$ (inclusive)\n",
    "\n",
    "    $$0 \\leq P(\\text{event}) \\leq 1$$\n",
    "    \n",
    "- The probabilities of all possible *outcomes* of an event will sum to $1$\n",
    "\n",
    "    $$P(\\text{first possibility}) + \\cdots + P(\\text{$n$th possibility}) = 1$$\n",
    "    \n",
    "    In the example of a coin flip, the two possibilities are Heads and Tails. Therefore, no matter whether or not the coin is fair, P(Heads) + P(Tails) will always sum to 1.\n",
    "    \n",
    "- From the above we can conclude that the probability that something *doesn't* happen is $1 - P(does happen)$, [explain this (?)]\n",
    "\n",
    "    $$P(\\text{not event}) = 1 - P(\\text{event})$$\n",
    "    \n",
    "- If we know that all outcomes are equally likely, we can calculate probabilities as\n",
    "\n",
    "    $$P(event) = \\frac{P(# of possibilities that satisfy the event)}{P(# of possibilities)}$$\n",
    "    \n",
    "    This is probably the form of probability you're most familiar with, as it pertains to many things like picking cards or rolling dice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
