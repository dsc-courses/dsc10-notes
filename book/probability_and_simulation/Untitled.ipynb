{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats, you've made it to the second half of this textbook. Let's start off by making a bold claim: *the study of probability is the key to tackling uncertainty*.\n",
    "\n",
    "What exactly does the study of probability entail? And if it's so powerful, how can we use computers to leverage that power?\n",
    "\n",
    "Let's dive in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities in our daily lives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply, a {dterm}`probability` is a measure of how likely something is to happen.\n",
    "\n",
    "We rely on likelihood in our daily lives whenever we're faced with a question that doesn't have a definite answer. These often come in the categories of questions about the future, [\"Can I get an A without going to class?\"], or questions subject to debate, [\"Does ...\", \"Did jury unfair?\"].\n",
    "\n",
    "While all of the questions we could possibly ask have some fundamental, universal truth, much like quantum physics the true answer remains unknown until it's been observed! This means, in order to get a 100% certain answer, we need to wait for the future or arrive, or for an investigation so thorough that there's not even a shred of doubt remaining.\n",
    "\n",
    "That's less than ideal. There must be a way to answer the question without waiting.\n",
    "\n",
    "Enter *probabilities*. In real life when we're faced with a question with an uncertain answer we usually offer whichever answer is *most likely*. We say things like, [\"I'm 80% sure that I can get an A\"], or [\"There's a pretty good chance the election was rigged.\"] How we arrive at that measure of '50%', and the math that lead us to 'pretty good chance' all boils down to calculating probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A semi-formal introduction to probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally, a probability of an event, written as $P(\\text{event})$ is the likelihood of an event expressed as a value between $0$ and $1$. A probability of $0$ means the event will theoretically never happen, $1$ means the event is theoretically certain to happen, and $0.5$ means the event is just as likely to happen or not happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, when we flip a fair coin, the probability that it lands showing Heads is $P(\\text{Heads}) = \\frac{1}{2}$ (or $0.5$ or $50\\%$). We know this intuitively, but let's formalize the math a little bit to figure out where that number comes from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "You may notice that probabilities are defined as between 0 and 1, but sometimes we use a percentage. Mathematically they're the same, $100\\% = 100 \\textit{ per cent} = \\frac{100}{100} = 1.$ But while percents can be nice in spoken language, you should stay consistent and always work with probabilities expressed as fractions or decimals between 0 and 1. This will make your life much easier and prevent you from pulling out your hair due to decimal place errors!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're learning about data *science*, let's define the terminology of probability in a scientific manner.\n",
    "\n",
    "Each time we flip a fair coin, we're essentially conducting an *experiment*. An {dterm}`experiment` is a process with a set of distinct possible {dterm}`outcomes`, only one of which can be the true result at a given time. We can conduct many trials of the experiment, but the each time we are uncertain which specific outcome will be the result. In this example, our experiment is a single coin flip and the possible outcomes are Heads and Tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All things equal\n",
    "\n",
    "In the case of flipping a coin, rolling a die, or any other experiment where all outcomes are equally likely, the probability of any given outcome is one divided by the total number of possible outcomes. So, for flipping a coin the probability of any outcome is $\\frac{1}{2}$, for a six-sided die the probability of any outcome is $\\frac{1}{6}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{equally-likely outcome}) = \\frac{1}{\\text{# of possible outcomes}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "If all outcomes of a process are equally likely, we usually call that process 'random'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, we'll use NumPy's `.random.choice` function to choose one outcome from a list of possible outcomes. The code below essentially conducts an experiment of a single coin flip by using NumPy, then checks if it landed on 'Heads' by using a {dterm}`comparison operator`. If we run the cell a bunch of times, we should expect that it'll return True roughly half of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "outcome = np.random.choice(['Heads', 'Tails'])\n",
    "\n",
    "outcome == 'Heads'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you tire your fingers running the cell dozens of times, you should know that NumPy makes it easy to run multiple trials of the experiment by specifying a second argument, `size=`. The result is an array of outcomes from each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed of zero results in 2 heads out of 10... could be useful.\n",
    "# np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[! should we introduce the for loop here instead?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = np.random.choice(['Heads', 'Tails'], size=10)\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And since we're working with an array we can do element-wise comparisons in order to check if each one is Heads or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes == 'Heads'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you know that you can count how many `True`s there are in a sequence by just taking the `sum` of that sequence? Let's try that now in order to find out how many of our ten coin flips resulted in Heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(outcomes == 'Heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collections of outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to something with more than two outcomes, like rolling a fair six-sided die. If you're playing a game that involes a die, you might be able to win if you roll a one *or* if you roll a two, so you'd be interested in the chances of getting either of these outcomes. The probability one-of-multiple outcomes occurring, like rolling a one or a two, is equal to the sum of each individual probability.\n",
    "\n",
    "$$P(\\text{one or two}) = P(\\text{one}) + P(\\text{two}) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}$$\n",
    "\n",
    "What you've just stumbled upon is called an *event*. An {dterm}`event` is a collection of outcomes where we're interested in finding the probability of any of those outcomes occurring. If we define the event $\\text{win}$ as rolling a one or a two, (often expressed in Set notation) $\\text{win} = \\{\\text{one, two}\\}$, then calculating the probability of $\\text{win}$ takes on the exact same calculation as above.\n",
    "\n",
    "$$P(\\text{win}) = P(\\{\\text{one, two}\\}) = P(\\text{one or two})$$\n",
    "\n",
    "From these two facts, it follows that the probability of any event is always just the sum of the probabilities of each outcome that satisfies the event.\n",
    "\n",
    "$$P(\\text{event}) = \\sum_{\\text{all outcomes in event}} P(\\text{outcome})$$\n",
    "\n",
    "When we're in the scenario of equally-likely outcomes, it so happens that it doesn't matter *which* outcomes are in our event, merely *how many* outcomes are in our event. By recognizing the repeated addition of $1$ in the numerator when the probabilities of two equally-likely outcomes are added, we can deduce a simpler way to calculate the probability of an event when outcomes are equally likely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{event with equally-likely outcomes}) = \\frac{\\text{# outcomes in event}}{\\text{total # possible outcomes}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[because it's based on counting how many possible outcomes there are and how many outcomes we're interested in (in our event), probability with all outcomes equally likely, often referred to as 'Classical Probability' is tackled primarily using combinatorics]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like an event can be broken down into multiple *or*'s mathematically, we can do the exact same thing in our code by using the `or` operator to string together multiple equality checks. In the code below, we're running an experiment of a single die roll, and checking if the winning event is satisfied by the roll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = np.random.choice([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "outcome == 1 or outcome == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Again, we can run multiple trials of the experiment and sum up the Trues] [we need to use the `|` operator (and parentheses!) when working with arrays though]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = np.random.choice(range(1,7), 10)\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(\n",
    "    (outcomes == 1) | (outcomes == 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humorously, we can also find the probability of the event containing zero outcomes. Asking for the probability of this empty event is essentially asking for the probability that our experiment produces none of the possible results thus violates all universal laws. If this sounds impossible to you, you're right. The probability of an empty event is zero. Whew, existential crisis avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other end of the spectrum, we could ask for the probability that any of our outcomes happen by specifying the event containing all outcomes. Necessarily our experiment must produce some form of outcome, so the probability of the [full event] is one. Because we also know that the probability of an event is equal to the sum of the probabilities of each outcome it contains, we can equivalently state that the probabilities of all possible outcomes sum to one.\n",
    "\n",
    "$$\\sum_{\\text{all outcomes}} P(\\text{outcome}) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the probability that some event does *not* happen is one minus the probability that it does. You can think of this as taking the [full event] and removing the event that we're interested in not happening.\n",
    "\n",
    "$$P(\\text{not event}) = 1 - P(\\text{event})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A general way to find probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code examples above, we ran an experiment many times and expected a certain number of them to satisfy our event because we already knew the probability of the event.\n",
    "\n",
    "What if we ran our code for flipping a coin 100 times and only saw that 20 of them showed up as Heads? Naturally we would start to suspect that the probability of flipping a Heads is closer to $0.2$ rather than $0.5$. Right?\n",
    "\n",
    "Aha! If you agreed, then you already know about the primary definition of probability that beginning data scientists use, called the 'frequentist' approach. This definition operates without the need for any assumptions about the likelihoods of our outcomes. We calculate the probability of some event happening as approximately the number of times we observed it divided by the total number of observations we made. This is often called the 'experimental probability' (to distinguish it from the universal truth that it approximates).\n",
    "\n",
    "$$P(\\text{event}) \\approx \\frac{\\text{# times event observed}}{\\text{total # observations}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remember our introduction to {dterm}`proportions` in Exploring Data, you'll notice that the calculation of an experimental probability is the exact same as the calculation of a proportion! [leverage computers to crunch probabilities] [This is mirrored in intuition]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approximation gets closer and closer to the true underlying probability as the number of observations increases. Formally, the equality holds once you've made infinite observations... in practice it can be pretty challenging to make infinite observations!\n",
    "\n",
    "Naturally, if you don't make many observations there's a good chance (!) that you'll calculate the incorrect probability simply due to randomness inherent to the experiment. You wouldn't expect to get exactly five Heads every time you flip ten coins. Furthermore, the fewer observations that are made, the more extreme each deviation seems, and the less precise our answer can be. If you only make ten observations, then a single unit change in the numerator causes a change of 0.1 (10%) in the resulting probability, and we can only be precise up to the nearest 0.1. Whereas if we were to make one-hundred observations, then we can be precise up to the nearest 0.01.\n",
    "\n",
    "Because it's never possible to make infinite observations, we need to be cognizant that we lose both accuracy and precision as the number of observations decreases -- we'll talk about how to deal with this more when we discuss sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated experiments and simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we made a statement relating to flipping a coin ten times and claiming you can find the probability that the coin will land on Heads.\n",
    "\n",
    "> \"if you don't make many observations there's a good chance that you'll calculate the incorrect probability simply due to randomness\"\n",
    "\n",
    "Any time you see the word 'chance', know that there is a probability that can be unearthed! In this scenario, we're looking for the probability that you flip a coin ten times and *don't* see exactly five Heads.\n",
    "\n",
    "Like before, we can use the frequentist approach to approximate this probability by defining a new experiment: *flip a coin ten times and record how many Heads showed up*, with a new set of outcomes: $\\text{Heads} = \\{0,1,\\ldots,10\\}$, specifying a desired event: $\\text{Heads} = \\{5\\}$, then conducting many trials and seeing how many observations satisfy our event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How do we flip a coin ten times and repeat that same process multiple times? The answer is called 'iteration' and comes in the form of a **for-loop**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for loop\n",
    "    - write the code for a single run of the experiment\n",
    "    - put it in a function\n",
    "    - call that function multiple times\n",
    "        - how to do that? for loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this simulation approach blends the classical and frequentist approaches\n",
    "    - classical for coin flip probability (using assumptions!)\n",
    "    - frequentist for prob of result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[! seems like this could easily segue into either distributions or HT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if you meet someone new, when does their birthday occur? (ignoring leap years)\n",
    "- unsure, a bit like Schrodinger's cat -- we don't know the truth until it is observed!\n",
    "- now is a good time for a 'probabilistic model'\n",
    "- assume that birthdays are uniformly distrbuted -- equally likely\n",
    "- with all possible outcomes equally likely, the probability of their birthday being on any given day is 1/365 (again, ignoring leap years)\n",
    "- we could find probabilities of an event -- a collection of outcomes\n",
    "- other math properties somehow\n",
    "- if we were to ask people we'd expect to find\n",
    "\n",
    "- but should we question the validity of our model?\n",
    "- say we're trying to determine which day is actually most likely for us to guess correct\n",
    "- we essentially do the reverse of our expectation -- welcome to the 'frequentist' approach\n",
    "- the probability is approximately the number of times observed over the number of trials -- getting closer to truth as the number of trials gets closer to infinity\n",
    "\n",
    "- we can't ask infinite people though! there are only 7bn people. Wait, we can't ask 7bn people either! Enter: sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"how many people got an A without going to class last quarter?\" -> take proportion -> frequentist approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[might not know underlying chance of outcomes]\n",
    "[frequentist]\n",
    "[our frequency might suggest unfair -- but 'is it fair' is another question of uncertainty that we can answer by asking what the chance is that we saw this result even if we *did* have a fair coin]\n",
    "\n",
    "[while there is math we can use, an arguably simpler approach is to simulate, and leverage computers]\n",
    "\n",
    "[notice that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilities and Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the second half of this textbook! Let's start off with a bold statement related to what we're about to learn.\n",
    "*The study of probability is the key to tackling uncertainty.*\n",
    "\n",
    "What does that mean? And, if it's true that probabilities are so powerful, then how can we use computers to leverage this power?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are probabilities, and why do we use them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've learned how to use Python and Babypandas to answer specific questions about our data -- questions that have a definite answer. Given the proper data set, we could answer a question like \"*how many people between the age of 30-40 have diabetes?*\". However, many of the decisions we face in life arise from questions that don't have such clear-cut answers, like \"*a 35 year old patient just walked into the doctors office, do they have diabetes?*\". The outcome of this question is subject to uncertainty -- we can't be sure of the truth until it's been observed.\n",
    "\n",
    "Instead of trying to give an absolute answer to these questions, we tackle them by finding *how likely* each possible outcome is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A {dterm}`probability` is simply a measurement representing how likely something is to happen. Probabilities range from $0$, meaning that thing will theorically never be happen, to $1$, meaning the event is theoretically certain to be observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency-based probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until you delve into upper division statistics courses, the realm of probabilities that we often operate in is the 'Frequentist' approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{event}) = \\frac{\\text{# outcomes in event}}{\\text{total # of equally likely outcomes}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{event}) = \\frac{\\text{# times event observed}}{\\text{total # of observations}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's entertain an example that we should all be familiar with: flipping a coin. Unbeknownst to most, flipping a coin is an incredibly complex process whose outcome depends on a nigh infinite number of factors: the starting orientation of the coin, the strength with which it's flipped, the presence of a breeze, the wear and tear of the coin... et cetera... all culminating with whether or not the catcher chooses to keep the coin resting in their palm or slap it on to the back of their other hand after they catch it! But in practice, we don't think about a coin flip this way. Not only is it infeasible to attempt to calculate all of those factors (lest even name them all!), but we can nicely summarize the coin flipping process with a simple {dterm}`probabilitistic model`: we expect that half of the time the coin will show Heads, and half of the time it will show Tails.\n",
    "\n",
    "The probability of a Heads is thus 0.5, written mathematically as $P(\\text{Heads})=0.5$. The probability of Tails is in this case the same, $P(\\text{Tails})=0.5$.\n",
    "\n",
    "In life we call processes like flipping a coin *random*, with outcomes that are subject to *chance*. Any time you hear these words, understand that a probabilistic model is at play, and therefore any questions about this process must be answered by working with the likelihood (probabilities) of each outcome using that model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conducting an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the coin flip example above, we knew the probabilities by assumption that the coin was fair. But what if we're the scrupulous type, and want to see for ourselves what the probabilities of flipping a Heads or Tails on a given coin truly is.\n",
    "\n",
    "In practice, we can find probabilities by conducting an experiment. In our experiment, we conduct multiple trials and keep track of how many times the particular event we're interested in occurs. For example, we could flip a coin ten times, and see how many times we get Heads. The probability of that event boils down to a simple form.\n",
    "\n",
    "$$\n",
    "P(\\text{event}) = \\frac{\\text{# of times event observed}}{\\text{# of observations}}\n",
    "$$\n",
    "\n",
    "It may come as no surprise that probabilities calculated this way are called *experimental probabilities*, as opposed to their theoretical, universal-truth counterparts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If in our hypothetical example we flip the coin $10$ times and we get Heads $3$ times, then we conclude that our experimental probability of getting a Heads is $P(\\text{Heads}) \\approx 0.3$. Since the only other possibility is Tails, then we conclude that our experimental probability of getting a Tails is $P(\\text{Tails}) \\approx 0.7$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Notice that when a probability is calculated it's impossible for us to observe the event less than $0$ times and also impossible to see it more times than the number of observations. Therefore we arrive at a first important rule -\n",
    "\n",
    "$$0 <= P <= 1$$]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[is our coin unfair?] [you may be tempted to think so, but it turns out there's a pretty good chance of us \n",
    "[what's the probability that we observe 3 out of 10 even with a fair coin?] [that's another experiment that we can conduct!] [in the mean time, it's probably best for us to just increase the number of trials]\n",
    "\n",
    "[as the number of trials goes up, we're more likely to get close to the actual underlying probability] [one way to think about the underlying theoretical probability is -- if there were an *infinite* nummber of observations, what would the empirical probability converge to?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_event_seen = 0\n",
    "trials = 10_000\n",
    "\n",
    "for i in range(trials):\n",
    "    flips = np.random.choice([True, False], 10)\n",
    "    if sum(flips) == 3:\n",
    "        times_event_seen += 1\n",
    "times_event_seen / trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The math of probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get too far ahead of ourselves, there are a couple properties that all probabilities satisfy which prove useful whenever you're working with them.\n",
    "\n",
    "- All probabilities are between $0$ and $1$ (inclusive)\n",
    "\n",
    "    $$0 \\leq P(\\text{event}) \\leq 1$$\n",
    "    \n",
    "- The probabilities of all possible *outcomes* of an event will sum to $1$\n",
    "\n",
    "    $$P(\\text{first possibility}) + \\cdots + P(\\text{$n$th possibility}) = 1$$\n",
    "    \n",
    "    In the example of a coin flip, the two possibilities are Heads and Tails. Therefore, no matter whether or not the coin is fair, P(Heads) + P(Tails) will always sum to 1.\n",
    "    \n",
    "- From the above we can conclude that the probability that something *doesn't* happen is $1 - P(does happen)$, [explain this (?)]\n",
    "\n",
    "    $$P(\\text{not event}) = 1 - P(\\text{event})$$\n",
    "    \n",
    "- If we know that all outcomes are equally likely, we can calculate probabilities as\n",
    "\n",
    "    $$P(event) = \\frac{P(# of possibilities that satisfy the event)}{P(# of possibilities)}$$\n",
    "    \n",
    "    This is probably the form of probability you're most familiar with, as it pertains to many things like picking cards or rolling dice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you progress as a data scientist, you'll take courses that revolve entirely around probabilities -- this is not that course. For now, only the very basics of formal probability theory needs to be introd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The exact same concept holds true when applied to problems that data scientists are tasked with.]\n",
    "\n",
    "[When faced with an outcome that you're uncertain about, the best tool we have at our disposal is to think about how likely each possible outcome is.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[pitfalls of probability -- not always immediately intuitive]] [test questions -- just as likely to get five C's as you are four C's followed by a A] [Monty Hall]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[how probability helps us solve problems -- introduce Monty Hall, motivate simulation!]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Python to simulate probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[one of the pitfalls of probability is that they're notoriously unintuitive]\n",
    "\n",
    "Often times it can be challenging to calculate exact probabilities using math -- and sometimes it's actually impossible! Here's where computers come to the rescue.\n",
    "\n",
    "If you're still unconvinced about the result of Monty Hall, we can run a simulation to compare the two choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code for a single trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "doors = np.random.choice(['Goat', 'Goat', 'Car'], size=3, replace=False)\n",
    "choice = np.random.choice([0, 1, 2])\n",
    "\n",
    "initial_guess = doors[choice]\n",
    "\n",
    "if initial_guess == 'Goat':\n",
    "    winning = 'Switch'\n",
    "elif initial_guess == 'Car':\n",
    "    winning = 'Stay'\n",
    "    \n",
    "winning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap it in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_monty_hall(do_switch=False):\n",
    "    \n",
    "    doors = np.random.choice(['Goat', 'Goat', 'Car'], size=3, replace=False)\n",
    "    choice = np.random.choice([0, 1, 2])\n",
    "\n",
    "    result = doors[choice]\n",
    "\n",
    "    if do_switch:\n",
    "        if result == 'Car':\n",
    "            result = 'Goat'\n",
    "        elif result == 'Goat':\n",
    "            result = 'Car'\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_monty_hall(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function a bunch of times. How do we do this? Using a concept called 'iteration' in the form of a **for-loop**. The syntax for running something many times is as follows.\n",
    "\n",
    "```html\n",
    "for i in range(<number_of_trials>):\n",
    "    <code_that_you_want_run_each_time>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to save our result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 1000\n",
    "\n",
    "yes_switch = []\n",
    "no_switch = []\n",
    "\n",
    "for i in range(trials):\n",
    "    yes = run_monty_hall(True)\n",
    "    no = run_monty_hall(False)\n",
    "    yes_switch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check how many times you should have switched, versus how many times you should have stayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
