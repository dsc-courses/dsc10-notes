{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters and statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- want to understand a metric of the population -- this is called a population parameter\n",
    "    - like average of numerical feature\n",
    "- use the metric computed on a representative sample as our best guess -- this is the sample statistic\n",
    "\n",
    "- sampling distribution is the distribution of sample statistics\n",
    "    - remember that every sample will be a bit different\n",
    "    - our illustration grows to add a third panel:\n",
    "        - Population distribution → many possible sample distributions drawn from population → each sample produces one statistic that updates our sampl*ing* distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "---\n",
    "# Old work / Staging area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we have a sample (the data)\n",
    "- we can create a sample from our assumed population (equally likely) by using np.random.choice\n",
    "- creating samples:\n",
    "    - from probabilities, arrays, or directly from from tables!\n",
    "    - with/without replacement\n",
    "    - sample size\n",
    "    - as size increases, samples look closer to the population\n",
    "        - this is like 'law of averages' that old book uses dice rolls to show -- each time we roll a die we're essentially sampling from the uniform probability distribution (could be thought of as sampling with replacement...). the more that we sample (i.e. the more rolls we make) the closer our observed sample distribution will look like the underlying, true probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we need pictures for this chapter!!!\n",
    "- we take a sample from that distribution -- more likely to pick a point from higher (more dense) areas, less likely to pick a point from lower areas\n",
    "- therefore the shape of our sample (if it's representative, large enough) *should* look pretty much the same as the general shape of our population\n",
    "- *but*, there's random chance involved! e.g., we might randomly pick more people from the low end\n",
    "- intuitively, if sometimes in each bin we randomly select more or less people, we'd expect that on average our sample should look pretty much like the population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- just ask what the birthdays are of all your teammates on your local hokey team -- turns out more hockey players born in Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- easter egg about Korean birthdays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://fivethirtyeight.com/features/some-people-are-too-superstitious-to-have-a-baby-on-friday-the-13th/\n",
    "- https://github.com/fivethirtyeight/data/tree/master/births\n",
    "\n",
    "Took 2000-2014 data, removed leap years (df.year %4 != 1), sum grouped by month,date_of_month, dropped year and day_of_week, added day_of_year index.\n",
    "\n",
    "Should probably include earlier data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import babypandas as bpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births = bpd.read_csv('../../data/us_total_births_2000-2014_no_leaps.csv')\n",
    "births.sort_values('births')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births.plot(kind='bar', x='day_of_year', y='births', width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births[(births.get('day_of_year') < 100) & (births.get('births') > 130000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hmmmmm... we should probably find something that has a hist associated with it that we can do sampling with. That way we have categorical and numerical distributions!\n",
    "- actually let's do this first. We can find a numerical distribution for another section -- like the predicting parameters and CLT chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add Continuous Distributions and Samples section\n",
    "- this could be like a \"why do samples look like the population\" thing\n",
    "- kinda just want to explain the whole \"if the histogram is higher then you're more likely to randomly pick an individual from that bin, vice-versa with lower\"-spiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: a fake birthday population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's create the true population distribution -- make it not uniform\n",
    "- then we sample from that (those are the people we collect data on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: products on a manufacturing line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- continuous numerical measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../data/FISH_TABLE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = df[(df.WT < 4000) & (df.WT >= 200)].sample(6100)\n",
    "s2 = df[(df.WT < 300) & (df.WT >= 150)].sample(480)\n",
    "s3 = df[(df.WT < 250) & (df.WT >= 50)].sample(320)\n",
    "s4 = df[(df.WT < 70) & (df.WT > 0)].sample(172)\n",
    "\n",
    "df2 = pd.concat([s1,s2,s3,s4])\n",
    "\n",
    "print(df2.shape)\n",
    "\n",
    "df2.plot.hist(y='WT', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd = df2[(df2.Species == 'STB')]\n",
    "ddd.TL = ddd.TL  / 10 # To cm #* 2.35 / 2\n",
    "ddd.WT = ddd.WT / 10 * 45.35 / 1000 # To kg\n",
    "\n",
    "ddd.plot(kind='scatter', x='TL', y='WT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(np.log10(ddd.TL.values * 10), np.log10(ddd.WT.values * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({\n",
    "    'ID': ['2019' + str(i+1).zfill(4) for i in range(df2.shape[0])],\n",
    "    'WEIGHT': (df2.WT.values / 10 * 50 / 1000).round(3), # Convert to kg\n",
    "    'LENGTH': (df2.TL.values / 10).round(1) # Convert to cm\n",
    "})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('../../data/fish_kg_cm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.WEIGHT.to_csv('../../data/fish_kg.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../../data/fish_kg_cm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
