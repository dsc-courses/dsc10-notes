{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the data sets that we are interested in are more complex that simple lists of numbers. For instance, consider a data set containing information about California wildfires. It might contain multiple pieces of data about each fire, including its name, size, location, and cause.\n",
    "\n",
    "How would we store and analyze such a data set? While we could use NumPy arrays -- one holding the fire's name, another holding the size, etc. -- there is a much better way: We will use a *table* to contain the data, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import babypandas as bpd\n",
    "fires = bpd.read_csv('../../data/calfire.csv')\n",
    "fires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like NumPy arrays, tables are provided by a third-party extension. The Python package which provides tables is called [pandas](https://pandas.pydata.org/). Pandas is *the* tool for doing data science in Python, and it is immensely popular -- as of Summer 2020, it was downloaded nearly *1 million* times per day. It is without a doubt a powerful tool, and you'll need to know how to use it if you want to do serious data science. But there's a problem: pandas is complicated. There are numerous ways to do even the simplest tasks. This makes it hard to learn, especially if you're new to programming.\n",
    "\n",
    "This leaves us in an interesting situation. On one hand, we want to learn pandas, because it is *the* tool used by actual data scientists. On the other hand, we don't want to be thrown into the deep end. The solution? We'll take pandas and remove everything that isn't absolutely necessary, resulting in something simpler and easier to learn. What's left is still *pandas* -- just not all of it. Because this new package is a smaller (and cuter) version of pandas, we're calling it *babypandas*.\n",
    "\n",
    "To get access to the functionality that *babypandas* provides, we'll need to import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import babypandas as bpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Remember that the syntax `import something as new_name` imports the package named `something`, giving it the new name `new_name`.\n",
    "It is a convention among data scientists to rename `pandas` to `pd` by writing `import pandas as pd`, so we will rename `babypandas` to `bpd`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "We're going to be using *babypandas* in the rest of this book, but it should be stressed that *babypandas* is *pandas*, just a smaller version of it. So if someone asks if you have experience working with *pandas* (during a job interview, for instance), you'll be able to say \"yes!\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *babypandas* (and *pandas*), a table is called a {dterm}`DataFrame` (though we'll use the two terms interchangeably). Since DataFrames are often used to store very large data sets, they are not typically created by typing their entries one by one -- instead, they are usually read from a file. We'll see how to do that in a moment, but for now we assume that we have already loaded a DataFrame into a variable called `fires`. If we type `fires` in our Jupyter notebook cell and execute it, it will display the table with nice formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we ask for the `type` of `fires`, Python will tell us that it is a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fires)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame consists of *columns* and *rows*. Almost always, a row represents a single thing -- in this case, a fire -- and the columns provide different pieces of information about that thing. In this case, we have a column describing the name of the fire, another describing the cause, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the number of rows and columns in a *DataFrame* by asking for its {dterm}`shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that there are 50 rows and 9 columns. If for whatever reason we just wanted the number of rows, we could ask for the first element of this pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every row and column in a DataFrame has a *label*. We will use the row and column labels to refer to particular parts of the table and retrieve information from within it. The columns of the above DataFrame are labeled \"year\", \"month\", \"cause\", and so on. The rows of the above table are simply labeled `0`, `1`, `2`, and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together, the row labels are called the {dterm}`table index`.\n",
    "By default, a table's rows are labeled by numbering them. However, in many cases it makes more sense to label the rows in some other way. For example, each row in our current data set is a single fire. Perhaps it makes more sense to use the fire's name as its row label. We can ask *babypandas* to use a particular column as the row labels with the `.set_index` method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "You might know that NumPy arrays can be two-dimensional, too, so they *could* be used to store tables. But NumPy arrays do not have an *index*.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires.set_index('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.set_index` method accepts one argument: the label of the column that should be used as the index. It then creates a *new* DataFrame in which the index has been replaced with the information from this column; the old DataFrame is not changed. In order to save the results, we'll need to assign the new table to a variable, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_by_name = fires.set_index('name')\n",
    "fires_by_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the fire names have been moved all the way to the left, and have been made bold -- this is *babypandas*' way of showing that these names are now the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**\n",
    "\n",
    "The index is *not* a column -- it is it's own separate thing. When we use `.set_index`, the old index is thrown out and number of columns decreases by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will later use row labels to refer to specific rows by name, the labels should be unique. In this case, that means that every fire should have a unique name. In this case, every fire is uniquely named, and it is fine to use the fire name as the index. Later, we'll see a larger version of this data set in which there are multiple fires with the same name. In that case, the name should probably not be used as the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A table's index is essentially an array. We can get the index by writing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_by_name.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then access individual elements of the index using the same notation as used with arrays, remembering that Python starts counting from zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first element\n",
    "fires_by_name.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the second element\n",
    "fires_by_name.index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last element\n",
    "fires_by_name.index[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
