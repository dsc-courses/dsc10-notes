{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now armed with a solid understanding of populations and samples, we can start to question about beliefs *about* populations and samples.\n",
    "\n",
    "Here's a basic motivating example: You flip a coin 10 times and only observe 3 Heads -- do you still believe the coin is fair? What if you flip it 100 times and observe 30 Heads? Or 1000 flips and 300 Heads? At what point is our observation *so weird* that we start to question our assumptions about the population these coin flips are coming from?\n",
    "\n",
    "In this chapter we'll introduce a framework to help us quantify how 'weird' an observation is, and help us decide if we should stick with or abandon our current set of beliefs about a population.\n",
    "\n",
    "However, as useful as coins are for teaching examples, we're not in the business of checking the fairness of coins. Data and statistics can be used to check assumptions in other, extraordinatily impactful fields, too..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swain v. Alabama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the local court of Talladega County, 1964, a black man by the name of Robert Swain was convicted by an all-white jury and sentenced to death. Swain appealed his sentence, arguing that the jury was not representative of his community and revealed a biased selection processess. In doing so, the case was soon elevated to the United States Supreme Court, arguing over *Swain v. Alabama*.\n",
    "\n",
    "By the U.S. Constitution, all people accused of a crime have the right to a fair jury, with a well-defined *fair* selection process. First, a pool of potential jurors are to be drawn representatively from the local population of eligible jurors -- as we know by now, \"representative\" implies *random*. After the initial, fair pool is drawn, the final panel of jurors is chosen, non-randomly, with direct intervention from the involved parties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time, the population of eligible jurors in Talladega County was about $26\\%$ black, yet in the initial pool of $100$ potential jurors, only $8$ selected were black -- whereas we would have expected that roughly $26$ members of the pool would be black. Such a discrepancy between the *observed* and the *expected* number of black candidates naturally gives rise to the question: *isn't that strange?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A need to quantify unlikely events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we haven't yet learned a way to definitely state how 'strange' this observation was. We might intuitively know that it's unlikely -- but *how unlikely*? In the court, that judgement was left to each unique person's personal beliefs about how random chance works. In the end, the Supreme Court decided that the disparity wasn't too unlikely, and didn't support the claim that there was a biased jury selection process. The claim was denied, and Swain's appeal along with it.\n",
    "\n",
    "Sure, we wouldn't expect to randomly select exactly twenty-six black members for the pool every single time, but *eight*? We may start to hypothesize that the sample was not in fact drawn from the entire population -- perhaps due to poor, or unjust sampling practices, the pool was selected from a subset of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competing hypotheses about the population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On one hand, we have an underlying assumption that the sample was drawn from the total population of Talladega County, having a population proportion of eligible black jurors equal to $26\\%$. Now we have a suspicion that the sampling might be biased, and in fact the jury pool was drawn from a population with an artificially lower population proportion of black members $< 26\\%$.\n",
    "\n",
    "These beliefs can be thought of as two competing *hypotheses* about the population which our data was generated from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The null hypothesis\n",
    "In the language of statistics, the first hypothesis is considered the {dterm}`null hypothesis` ($H_0$). The 'null' is a hypothesis about some population parameter which our initial assumptions and models are built on. The null is assumed to be true at the outset of our experiment, but it is our job to be critical of the null hypothesis, and ask whether or not we should stick with our assumptions, or find new ones.\n",
    "\n",
    "When we were presented with the problem, we operated under the *model* our sample was generated randomly from a population with the proportion of black members equal to $26\\%$. These assumptions lead us to define our null hypothesis about the sampled population as:\n",
    "\n",
    "$$\n",
    "H_0: P(\\text{juror is black}) = 0.26\n",
    "$$\n",
    "\n",
    "Under this hypothesis, any difference between our observed sample statistic and the assumed population parameter are due to no other reason than random chance in our sampling.\n",
    "\n",
    "This is the official proposal put forth by the Supreme Court -- that we collected a sample of $100$ individuals from a population that was $26\\%$ black, and managed to only observe $8$ black members *purely by random chance*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The alternate hypothesis\n",
    "Since we're critical of the null hypothesis, we propose an {dterm}`alternate hypothesis` ($H_1$) which contradicts the null. The alternate hypothesis is essentially the set of beliefs we'll choose to adopt if it appears that our null hypothesis is too unlikely to be true. \n",
    "\n",
    "The alternate hypothesis proposes a model where differences between the observed sample statistic and the assumed population parameter are due to some reason *other than randomness*.\n",
    "\n",
    "In examining Swain v. Alabama, we contradict the null proposing that the jury pool was sampled from a population with artificially less than $26\\%$ black members:\n",
    "\n",
    "$$\n",
    "H_1: P(\\text{juror is black}) < 0.26\n",
    "$$\n",
    "\n",
    "If it appears that random chance alone couldn't have produced the observed number of black jury pool members that we saw in the case, then we'll move to this belief -- that we managed to observe only $8$ black members because the population we sampled from was less than fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As data scientists, we don't just tell the ~myths~ hypotheses, we put them to the test!\n",
    "\n",
    "Given an observed sample statistic -- like 8 black members out of 100 -- and a potential population the sample came frome -- like a population that is 26% black -- we can test whether or not the sample likely came from that population. Here's the general framework:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. By conducting a {dterm}`hypothesis test`, we can decide whether or not to abandon the beliefs of our null hypothesis. Simply, this is done by calculating how unlikely our *observed sample statistic* is under the assumptions of the null.\n",
    "\n",
    "Note the significance of the null hypothesis in this context -- it provides a model *under which we can generate data*.\n",
    "\n",
    "2. Under the null hypothesis, we can use our simulation know-how to create new random samples with the same conditions that the original jury pool supposedly followed.\n",
    "\n",
    "3. Using our probability know-how, we estimate the probability that this null model could produce a sample statistic as 'strange' as the one we originally observed.\n",
    "\n",
    "4. If it's too unlikely, we reject the null hypothesis and move our beliefs over to the alternate hypothesis. Otherwise, if it's decently likely then we have no reason to abandon the assumptions of the null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it *could have happened*, but it's *so unlikely* to happen that we choose to believe there's something besides random chance involved\n",
    "- that *so unlikely* threshold is the level of significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we don't have access to the population\n",
    "- need a way to see which hypothesis we should embrace\n",
    "- not necessarily which one is true, just which we'll choose to belive as the result of our experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [HT procedures]\n",
    "    - one-sided? two-sided?\n",
    "    - introduction of a 'test statistic'\n",
    "    - basically, comparing the sampling distribution of the test statistic from the hypothesized (null) population to the observed statistic from our sample, which *may perhaps* suggest that our population is potentially-different (alternate) from what we thought\n",
    "    - generalize the procedures at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a sample statistic as 'the number of Heads received in 100 coin flips' and simulate the sampling distribution under the assumption that our coin is fair. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among their official statements, which you can find [here](https://tile.loc.gov/storage-services/service/ll/usrep/usrep380/usrep380202/usrep380202.pdf) if you are so inclined, the following are notable:\n",
    "> \"The overall percentage disparity has been small, and reflects no studied attempt to include or exclude a specified number of Negroes.\" (p. 209)\n",
    "\n",
    "> \"Even if a State's systematic striking of Negroes in selecting trial juries raises a prima facie case of discrimination under the Fourteenth Amendment the record here is insufficient to establish such systematic striking in the county.\" (p. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import babypandas as bpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for a single trial\n",
    "def run_sample_statistic():\n",
    "    \n",
    "    # Sample (with replacement) from the probability distribution of a fair coin\n",
    "    flips = np.random.choice(['Heads', 'Tails'], replace=True, size=100)\n",
    "    \n",
    "    # And compute the statistic: number of Heads\n",
    "    statistic = (flips == 'Heads').sum()\n",
    "    \n",
    "    return statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct an experiment, keeping track of the sampling distribution\n",
    "statistics = []\n",
    "\n",
    "for i in range(10_000):\n",
    "    statistics.append(run_sample_statistic())\n",
    "    \n",
    "num_heads = np.array(statistics)\n",
    "    \n",
    "# And plot the sampling distribution\n",
    "bpd.Series(data=num_heads).plot(\n",
    "    kind='hist', bins=np.arange(25, 76), density=True,\n",
    "    title='Sampling Distribution of # Heads in 100 Fair Coin Flips'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_heads == 50).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The birthday problem revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we're now ready to return to assumption -- *are all birthdays in the U.S. actually equally likely?* Again, ignoring leap years for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to put this in terms of populations, we're hypothesizing that the true population distribution of all birthdays in the United States is *uniform*.\n",
    "- ![hypothesized population distribution]\n",
    "- but, we don't have data from the entire U.S. populace. Time to look at our sample\n",
    "    - maybe some issues with the sample -- only recentish years, isn't random like what we're used to...\n",
    "- the sample looks decidedly not uniform\n",
    "    - point out some of the interesting bits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- two hypotheses:\n",
    "    - 0: Population is uniform\n",
    "    - 1: Population is not uniform\n",
    "- need a way to capture the difference of a distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A new test statistic: *total variation distance*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [rewrite hypotheses with tvd]\n",
    "- [conduct HT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncovering racial bias with the total variation distance\n",
    "\n",
    "- the hypothesis testing framework works with *any test statistic*, and the total variation distance is a great test statistic for categorical distributions \n",
    "- [jury selection]\n",
    "\n",
    "- remember: poor sampling techniques essentially alter the population which the data represents -- so we're curious if the 'population' of selected jurors actually matches the population of the U.S., or if their selection process artificially excluded certain members from being part of the population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Staging area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
